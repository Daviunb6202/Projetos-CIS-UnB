{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Daviunb6202/Projetos-CIS-UnB/blob/main/Projeto_4_CIS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "mHMTvdYcWpLX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import sklearn as sk \n",
        "import matplotlib.pyplot as plt \n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import gdown\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import time\n",
        "from sklearn.utils import check_array, check_random_state\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwfFj9z_XeH6",
        "outputId": "41ba6d22-d275-4dd8-cf89-e511664965e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Access denied with the following error:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=15Ejc7ttoyHERT8pj_s7GSTdpQCJ-MHao \n",
            "\n"
          ]
        }
      ],
      "source": [
        "gdown.download('https://drive.google.com/uc?id=15Ejc7ttoyHERT8pj_s7GSTdpQCJ-MHao', output=None, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "id": "k0loTDXFYMbx",
        "outputId": "3a45b4d0-e869-478b-9729-78a6b63da742"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
            "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
            "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
            "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
            "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
            "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
            "\n",
            "[5 rows x 31 columns]                 Time            V1  ...         Amount          Class\n",
            "count  284807.000000  2.848070e+05  ...  284807.000000  284807.000000\n",
            "mean    94813.859575  3.918649e-15  ...      88.349619       0.001727\n",
            "std     47488.145955  1.958696e+00  ...     250.120109       0.041527\n",
            "min         0.000000 -5.640751e+01  ...       0.000000       0.000000\n",
            "25%     54201.500000 -9.203734e-01  ...       5.600000       0.000000\n",
            "50%     84692.000000  1.810880e-02  ...      22.000000       0.000000\n",
            "75%    139320.500000  1.315642e+00  ...      77.165000       0.000000\n",
            "max    172792.000000  2.454930e+00  ...   25691.160000       1.000000\n",
            "\n",
            "[8 rows x 31 columns] (284807, 31)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a2b1f674-3d36-4798-b1b6-9833709a13f5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284802</th>\n",
              "      <td>172786.0</td>\n",
              "      <td>-11.881118</td>\n",
              "      <td>10.071785</td>\n",
              "      <td>-9.834783</td>\n",
              "      <td>-2.066656</td>\n",
              "      <td>-5.364473</td>\n",
              "      <td>-2.606837</td>\n",
              "      <td>-4.918215</td>\n",
              "      <td>7.305334</td>\n",
              "      <td>1.914428</td>\n",
              "      <td>4.356170</td>\n",
              "      <td>-1.593105</td>\n",
              "      <td>2.711941</td>\n",
              "      <td>-0.689256</td>\n",
              "      <td>4.626942</td>\n",
              "      <td>-0.924459</td>\n",
              "      <td>1.107641</td>\n",
              "      <td>1.991691</td>\n",
              "      <td>0.510632</td>\n",
              "      <td>-0.682920</td>\n",
              "      <td>1.475829</td>\n",
              "      <td>0.213454</td>\n",
              "      <td>0.111864</td>\n",
              "      <td>1.014480</td>\n",
              "      <td>-0.509348</td>\n",
              "      <td>1.436807</td>\n",
              "      <td>0.250034</td>\n",
              "      <td>0.943651</td>\n",
              "      <td>0.823731</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284803</th>\n",
              "      <td>172787.0</td>\n",
              "      <td>-0.732789</td>\n",
              "      <td>-0.055080</td>\n",
              "      <td>2.035030</td>\n",
              "      <td>-0.738589</td>\n",
              "      <td>0.868229</td>\n",
              "      <td>1.058415</td>\n",
              "      <td>0.024330</td>\n",
              "      <td>0.294869</td>\n",
              "      <td>0.584800</td>\n",
              "      <td>-0.975926</td>\n",
              "      <td>-0.150189</td>\n",
              "      <td>0.915802</td>\n",
              "      <td>1.214756</td>\n",
              "      <td>-0.675143</td>\n",
              "      <td>1.164931</td>\n",
              "      <td>-0.711757</td>\n",
              "      <td>-0.025693</td>\n",
              "      <td>-1.221179</td>\n",
              "      <td>-1.545556</td>\n",
              "      <td>0.059616</td>\n",
              "      <td>0.214205</td>\n",
              "      <td>0.924384</td>\n",
              "      <td>0.012463</td>\n",
              "      <td>-1.016226</td>\n",
              "      <td>-0.606624</td>\n",
              "      <td>-0.395255</td>\n",
              "      <td>0.068472</td>\n",
              "      <td>-0.053527</td>\n",
              "      <td>24.79</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284804</th>\n",
              "      <td>172788.0</td>\n",
              "      <td>1.919565</td>\n",
              "      <td>-0.301254</td>\n",
              "      <td>-3.249640</td>\n",
              "      <td>-0.557828</td>\n",
              "      <td>2.630515</td>\n",
              "      <td>3.031260</td>\n",
              "      <td>-0.296827</td>\n",
              "      <td>0.708417</td>\n",
              "      <td>0.432454</td>\n",
              "      <td>-0.484782</td>\n",
              "      <td>0.411614</td>\n",
              "      <td>0.063119</td>\n",
              "      <td>-0.183699</td>\n",
              "      <td>-0.510602</td>\n",
              "      <td>1.329284</td>\n",
              "      <td>0.140716</td>\n",
              "      <td>0.313502</td>\n",
              "      <td>0.395652</td>\n",
              "      <td>-0.577252</td>\n",
              "      <td>0.001396</td>\n",
              "      <td>0.232045</td>\n",
              "      <td>0.578229</td>\n",
              "      <td>-0.037501</td>\n",
              "      <td>0.640134</td>\n",
              "      <td>0.265745</td>\n",
              "      <td>-0.087371</td>\n",
              "      <td>0.004455</td>\n",
              "      <td>-0.026561</td>\n",
              "      <td>67.88</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284805</th>\n",
              "      <td>172788.0</td>\n",
              "      <td>-0.240440</td>\n",
              "      <td>0.530483</td>\n",
              "      <td>0.702510</td>\n",
              "      <td>0.689799</td>\n",
              "      <td>-0.377961</td>\n",
              "      <td>0.623708</td>\n",
              "      <td>-0.686180</td>\n",
              "      <td>0.679145</td>\n",
              "      <td>0.392087</td>\n",
              "      <td>-0.399126</td>\n",
              "      <td>-1.933849</td>\n",
              "      <td>-0.962886</td>\n",
              "      <td>-1.042082</td>\n",
              "      <td>0.449624</td>\n",
              "      <td>1.962563</td>\n",
              "      <td>-0.608577</td>\n",
              "      <td>0.509928</td>\n",
              "      <td>1.113981</td>\n",
              "      <td>2.897849</td>\n",
              "      <td>0.127434</td>\n",
              "      <td>0.265245</td>\n",
              "      <td>0.800049</td>\n",
              "      <td>-0.163298</td>\n",
              "      <td>0.123205</td>\n",
              "      <td>-0.569159</td>\n",
              "      <td>0.546668</td>\n",
              "      <td>0.108821</td>\n",
              "      <td>0.104533</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284806</th>\n",
              "      <td>172792.0</td>\n",
              "      <td>-0.533413</td>\n",
              "      <td>-0.189733</td>\n",
              "      <td>0.703337</td>\n",
              "      <td>-0.506271</td>\n",
              "      <td>-0.012546</td>\n",
              "      <td>-0.649617</td>\n",
              "      <td>1.577006</td>\n",
              "      <td>-0.414650</td>\n",
              "      <td>0.486180</td>\n",
              "      <td>-0.915427</td>\n",
              "      <td>-1.040458</td>\n",
              "      <td>-0.031513</td>\n",
              "      <td>-0.188093</td>\n",
              "      <td>-0.084316</td>\n",
              "      <td>0.041333</td>\n",
              "      <td>-0.302620</td>\n",
              "      <td>-0.660377</td>\n",
              "      <td>0.167430</td>\n",
              "      <td>-0.256117</td>\n",
              "      <td>0.382948</td>\n",
              "      <td>0.261057</td>\n",
              "      <td>0.643078</td>\n",
              "      <td>0.376777</td>\n",
              "      <td>0.008797</td>\n",
              "      <td>-0.473649</td>\n",
              "      <td>-0.818267</td>\n",
              "      <td>-0.002415</td>\n",
              "      <td>0.013649</td>\n",
              "      <td>217.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>284807 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2b1f674-3d36-4798-b1b6-9833709a13f5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a2b1f674-3d36-4798-b1b6-9833709a13f5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a2b1f674-3d36-4798-b1b6-9833709a13f5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            Time         V1         V2  ...       V28  Amount  Class\n",
              "0            0.0  -1.359807  -0.072781  ... -0.021053  149.62      0\n",
              "1            0.0   1.191857   0.266151  ...  0.014724    2.69      0\n",
              "2            1.0  -1.358354  -1.340163  ... -0.059752  378.66      0\n",
              "3            1.0  -0.966272  -0.185226  ...  0.061458  123.50      0\n",
              "4            2.0  -1.158233   0.877737  ...  0.215153   69.99      0\n",
              "...          ...        ...        ...  ...       ...     ...    ...\n",
              "284802  172786.0 -11.881118  10.071785  ...  0.823731    0.77      0\n",
              "284803  172787.0  -0.732789  -0.055080  ... -0.053527   24.79      0\n",
              "284804  172788.0   1.919565  -0.301254  ... -0.026561   67.88      0\n",
              "284805  172788.0  -0.240440   0.530483  ...  0.104533   10.00      0\n",
              "284806  172792.0  -0.533413  -0.189733  ...  0.013649  217.00      0\n",
              "\n",
              "[284807 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "credit = pd.read_csv('creditcard.csv', sep=',')\n",
        "credit = pd.DataFrame(credit)\n",
        "print(credit.head(), credit.describe(), credit.shape) \n",
        "credit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhUwGz_4jy14",
        "outputId": "5e2c3a1c-ec22-4120-cf67-caa5c4dd8318"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owltfBfkbOik",
        "outputId": "50c8d5e8-27fe-44df-b1e6-7cda2ab9bc53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               V1         V2        V3  ...       V26       V27       V28\n",
            "0       -1.359807  -0.072781  2.536347  ... -0.189115  0.133558 -0.021053\n",
            "1        1.191857   0.266151  0.166480  ...  0.125895 -0.008983  0.014724\n",
            "2       -1.358354  -1.340163  1.773209  ... -0.139097 -0.055353 -0.059752\n",
            "3       -0.966272  -0.185226  1.792993  ... -0.221929  0.062723  0.061458\n",
            "4       -1.158233   0.877737  1.548718  ...  0.502292  0.219422  0.215153\n",
            "...           ...        ...       ...  ...       ...       ...       ...\n",
            "284802 -11.881118  10.071785 -9.834783  ...  0.250034  0.943651  0.823731\n",
            "284803  -0.732789  -0.055080  2.035030  ... -0.395255  0.068472 -0.053527\n",
            "284804   1.919565  -0.301254 -3.249640  ... -0.087371  0.004455 -0.026561\n",
            "284805  -0.240440   0.530483  0.702510  ...  0.546668  0.108821  0.104533\n",
            "284806  -0.533413  -0.189733  0.703337  ... -0.818267 -0.002415  0.013649\n",
            "\n",
            "[284807 rows x 28 columns]\n",
            "[0 1]\n",
            "(284807, 28) (284807,)\n"
          ]
        }
      ],
      "source": [
        "import sklearn.model_selection as ml\n",
        "credit.dropna(axis=0, inplace = True)\n",
        "#credit.drop([1], inplace=True)\n",
        "\n",
        "X_full = credit.iloc[:,1:-2]\n",
        "print(X_full)\n",
        "y1 = credit.iloc[:,-1]\n",
        "y2 = credit.iloc[:,-2]\n",
        "\n",
        "print(np.unique(y1))\n",
        "\n",
        "#print(y1[y1==1])\n",
        "print(X_full.shape, y1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "#Usando do tecnica de proporcao de labels sinteticas\n",
        "#Apenas a maioria nao sofrera sampling\n",
        "smote = SMOTE(k_neighbors =1)\n",
        "#Valor do parametro muda conforme o numero de linhas selecionadas do dataset\n",
        "X_sm, y_sm = smote.fit_resample(X_full,y1)\n",
        "y_sm.value_counts()\n",
        "\n",
        "X_sm = X_sm.sample(500)\n",
        "y_sm = y_sm.sample(500)"
      ],
      "metadata": {
        "id": "CtlU_qloccXT"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wI7m2LKc2fG",
        "outputId": "c9d46777-0e6c-41bb-a01d-e047f3debb3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(400, 28) (400,)\n"
          ]
        }
      ],
      "source": [
        "#X_full = X_full.sample(500)\n",
        "#y1 = y1.sample(500)\n",
        "X_train, X_test, y_train, y_test = ml.train_test_split(X_sm, y_sm, test_size = 0.2, random_state=43)\n",
        "\n",
        "y_train.value_counts()\n",
        "print(X_train.shape, y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "ShiO7wDcAIEj"
      },
      "outputs": [],
      "source": [
        "#Cada função aqui está com lidando com erros de processamento igualando resultados de infinito a 1 \n",
        "# e resultados de nan a 0\n",
        "\n",
        "\n",
        "#Funções de ativação\n",
        "def relu(x):\n",
        "  z1 = np.maximum(0, x)\n",
        "  z = [1 if (np.isinf(z) == True) else z for z in z1]\n",
        "  z = [0 if (np.isnan(z) == True) else z for z in z1]\n",
        "  return z \n",
        " #sua derivada é np.heaviside(x1 = x, x2 = 0)\n",
        "\n",
        "def relu_derivative(x):\n",
        "  for i in range(len(x)):\n",
        "     x[i]<=0 \n",
        "     x[i]<= 1\n",
        "     x = [1 if (np.isinf(z) == True) else z for z in x]\n",
        "     x = [0 if (np.isnan(z) == True) else z for z in x]\n",
        "     return x\n",
        "\n",
        "#função de ativação de output \n",
        "def sigmoid(x):\n",
        "  z =  np.where(x < 0, np.exp(x)/(1 + np.exp(x)), 1/(1 + np.exp(-x))) \n",
        "  if np.isinf(z) == True:\n",
        "    z = 1\n",
        "  elif np.isnan(z) == True:\n",
        "    z = 0\n",
        "  else:\n",
        "    z = z \n",
        "  return z\n",
        "   \n",
        " #sua derivada é \n",
        "def sigma_derivative(z):\n",
        "  d = sigmoid(z)\n",
        "  x = d-d*d\n",
        "  if np.isinf(x) == True:\n",
        "    x = 1 \n",
        "  elif np.isnan(x) == True:\n",
        "    x = 0\n",
        "  else:\n",
        "    x = x  \n",
        "  return x\n",
        " \n",
        " \n",
        "#função de perda \n",
        "def bc_entropy(y_pred, y_train):\n",
        "  loss = -(y_train * np.log(y_pred) + (1 - y_train) * np.log(1 - y_pred)).mean()\n",
        "  if np.isinf(loss) == True:\n",
        "        loss = 1 \n",
        "  elif np.isnan(loss) == True:\n",
        "    loss = 0\n",
        "  else:\n",
        "    loss = loss  \n",
        "  return loss\n",
        "\n",
        "#derivada da função de perda\n",
        "def bc_entropy_derivative(y_pred, y_train, z):\n",
        "  loss = (y_train - y_pred)*z\n",
        "  if np.isinf(loss) == True:\n",
        "        loss = 1 \n",
        "  elif np.isnan(loss) == True:\n",
        "    loss = 0\n",
        "  else:\n",
        "    loss = loss  \n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "1qjz_XfKZUa3"
      },
      "outputs": [],
      "source": [
        "class mlp(sk.base.BaseEstimator, sk.base.ClassifierMixin):\n",
        "\n",
        "#Classificação binária para prever fraudes nas transações com\n",
        "#cartões de crédito usando um Perceptron com uma camada\n",
        "#oculta feito somente com numpy:\n",
        "  def __init__(self, n_neurons, max_iter, learning_rate): #classe iniciada com seus parametros principais\n",
        "    self.n_neurons = n_neurons\n",
        "    self.max_iter = max_iter\n",
        "    self.learning_rate = learning_rate\n",
        "\n",
        "  def choose_random_sample(X, random_state=0):\n",
        "      X = check_array(X)\n",
        "      random_state = check_random_state(random_state)\n",
        "      i = random_state.randint(X.shape[0])\n",
        "      return X[i]\n",
        "\n",
        "  def get_params(self, deep=True):\n",
        "    #a função get params e set params para compatibilidade com o sklearn\n",
        "    return {\"n_neurons\": self.n_neurons, \"max_iter\": self.max_iter, \"learning_rate\": self.learning_rate}\n",
        "\n",
        "  def set_params(self, **parameters):\n",
        "      for parameter, value in parameters.items():\n",
        "          setattr(self, parameter, value)\n",
        "      return self\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #inicialização dos pesos, vieses e valores de ativação\n",
        "  #randomização dos valores das duas matrizes a partir da tabela normal\n",
        "  #uma coluna de vieses no final, começando a partir do zero\n",
        "  #tudo isso com o cuidado de ser apenas na primeira iteração da primeira época\n",
        "  def network_config_(self, row, X, e):\n",
        "    row_values = X.iloc[row,:]\n",
        "    self.len_row_values = len(row_values)\n",
        "    if row == 0 and e == 0:\n",
        "      self.biases1 = np.zeros(shape=(self.n_neurons, 1))\n",
        "      shape1 = self.n_neurons*len(row_values)\n",
        "      self.matrix1 = np.array(np.random.normal(0,1, (shape1))).reshape(self.n_neurons, len(row_values))\n",
        "      self.matrix2 = np.array(np.random.normal(0,1, (self.n_neurons))).reshape(1, self.n_neurons)   \n",
        "      self.a_column1 = np.array(row_values)\n",
        "      self.a_column2 = np.zeros(shape=(self.n_neurons,1))\n",
        "      self.a_column3 = np.zeros(shape=(1,1))\n",
        "    else:\n",
        "      self.a_column1 = np.array(row_values)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def feedfoward_(self):\n",
        "    #multiplicação de matrizes e depois função de ativação ReLu, já para o output a função é sigmóide, acrescenta-se os vieses e depois\n",
        "    #soma-se todos os valores\n",
        "    z = np.dot(self.a_column1, self.matrix1.T)\n",
        "    self.a_column2 = relu(z)\n",
        "    z = sum(np.dot(self.a_column2,self.matrix2.T) + self.biases1)\n",
        "    self.a_column3 = float(sigmoid(z.real))\n",
        "    a_column3_proba = self.a_column3\n",
        "    return a_column3_proba\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def backpropagation_(self, learning_rate, predicts, y_train):\n",
        "    #aqui toma-se cuidado para buscar a formula de derivação por regra da cadeia dos vieses da matriz 1, da matriz 2, e os pesos em si\n",
        "    #pra isso derivasse as funções de ativação e até as de custo\n",
        "    # a learning rate controla o quanto as matrizes se atualizam com os novos valores\n",
        "    z1 = np.dot(self.a_column1, self.matrix1.T)\n",
        "    z = [1 if (np.isinf(z) == True) else float(z).real for z in z1] \n",
        "    derv_loss = np.empty(shape=(self.n_neurons,1))\n",
        "\n",
        "    #Derivada da função custo pela variavel predição\n",
        "    for row in range(len(y_train)):\n",
        "      for n in range(self.n_neurons): \n",
        "        loss = bc_entropy_derivative(predicts[row], y_train.iloc[row], z[n])\n",
        "      derv_loss += loss   \n",
        "    derv_loss = derv_loss*(-1/len(y_train))\n",
        "\n",
        "    derv_weight_output = np.zeros(shape=(self.matrix2.shape)) \n",
        "    derv_bias1 = np.zeros(shape=(self.n_neurons,1))\n",
        "    derv_weight_input = np.zeros(shape=(self.matrix1.shape))\n",
        "\n",
        "    relu1 = relu(z)\n",
        "    #derivada da ativação \n",
        "    derv_relu = relu_derivative(z)\n",
        "    derv_relu = [1 if (np.isinf(z) == True) else z for z in derv_relu]\n",
        "    derv_relu = [0 if (np.isnan(z) == True) else z for z in derv_relu]\n",
        "    #print(f'1:{z},\\n2:{relu1},\\n3:{derv_loss}')\n",
        "\n",
        "    #Cálculo da regra da cadeia\n",
        "    for n in range(self.n_neurons):\n",
        "      \n",
        "      #derivada do custo em relação aos pesos da matriz2  = derivada do custo pela predição vezes derivada da função de ativação\n",
        "      derv_weight_output[0][n] = derv_loss[n]*relu1[n]      \n",
        "      derv_bias1[n] = derv_loss[n]\n",
        "      for n2 in range(self.len_row_values):\n",
        "        #derivada do custo em relação aos pesos da matriz1  = derivada do custo pela predição vezes pesos da matriz 1 vezes... \n",
        "        #...derivada da ativação vezes input\n",
        "        derv_weight_input[n][n2] = derv_loss[n]*self.matrix2[0][n]*derv_relu[n]*self.a_column1[n2]\n",
        "    \n",
        "    #Atualizações \n",
        "    self.matrix1 -= derv_weight_input*learning_rate \n",
        "    self.biases1 -= derv_bias1*learning_rate\n",
        "    self.matrix2 -= derv_weight_output*learning_rate\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    #cópia para não afetar os dataframes originais\n",
        "    #checagem de se tratar do pandas e não numpy\n",
        "    #cálculo do valor de custo pro gradiente\n",
        "    #para cada época temos as iterações do feedfoward e depois as do backpropagation\n",
        "    X_train = X.copy()\n",
        "    y_train = y.copy()\n",
        "    X_train = pd.DataFrame(X_train)\n",
        "    y_train = pd.Series(y_train)\n",
        "    self.classes_ = np.unique(y)\n",
        "    row_values = X_train.iloc[:,0]\n",
        "    #Iteração para cada época----------------------------------------------------------\n",
        "    for n_iter in range(self.max_iter):\n",
        "      predicts = np.empty(shape=(y_train.shape))\n",
        "      losses = np.empty(shape=(y_train.shape))\n",
        "    #Parte do feedfoward \n",
        "      for row in range(len(X_train.iloc[:,0])):\n",
        "        mlp.network_config_(self, row, X_train, n_iter) \n",
        "        proba = mlp.feedfoward_(self)\n",
        "        predicts[row] = proba\n",
        "        losses[row] = bc_entropy(y_pred = proba, y_train = y_train.iloc[row])\n",
        "\n",
        "    #Parte do backpropagation\n",
        "      for row2 in range(len(y_train.iloc[:])):\n",
        "        row_values = X_train.iloc[row,:]\n",
        "        self.a_column1 = np.array(row_values)\n",
        "        mlp.backpropagation_(self, self.learning_rate, predicts, y_train)\n",
        "    \n",
        "    t1 = time.time()\n",
        "    print(f' Tempo gasto: {t1- t0}, {losses}')\n",
        "    #-------------------------------------------------------------------------------------   \n",
        "    #print(f'1: {self.matrix1},\\n\\n\\n 2:{self.matrix2}, \\n\\n 3:{self.biases1}')\n",
        "    mlp.matrix1_ = self.matrix1\n",
        "    mlp.matrix2_ = self.matrix2 \n",
        "    mlp.biases_ = self.biases1\n",
        "    return self\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def predict(self, X):\n",
        "    #iterações com base no X teste, dessa vez as predições de antes são usadas não pela função de custo, mas como resultado\n",
        "    #sk.utils.validation.check_is_fitted(self)\n",
        "    self.matrix1 = mlp.matrix1_\n",
        "    self.matrix2 = mlp.matrix2_ \n",
        "    self.biases1 = mlp.biases1_\n",
        "    X = sk.utils.check_array(X)\n",
        "    X_test = pd.DataFrame(X)\n",
        "    predicts=[]\n",
        "    for row in range(len(X_test.iloc[:,0])):\n",
        "      row_values = X_test.iloc[row,:] \n",
        "      a_column1 = np.array(row_values)\n",
        "      proba = mlp.feedfoward_(self)\n",
        "      np.append(np.asarray(predicts), proba[0])\n",
        "    return predicts\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def score(self, pred, y=None):\n",
        "    #calcular a eficiência - só é valido se o dataset estiver balanceado  \n",
        "    equals = pred[pred==y]\n",
        "    equals = np.asarray(equals)\n",
        "    self.accuracy = 100*sum(equals)/len(y)\n",
        "    return self.accuracy\n",
        "\n",
        "\n",
        "\n",
        "#from sklearn.utils.estimator_checks import check_estimator\n",
        "#check_estimator(mlp(n_neurons= 10, max_iter = 10, learning_rate= 0.01))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t0 = time.time()\n",
        "m = mlp(n_neurons = 10, max_iter =3, learning_rate = 0.01)\n",
        "m.fit(X_train, y_train)\n",
        "predict = m.predict(X_test)\n",
        "accuracy = m.score(predict, y_test)\n",
        "predict\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "onYYAjiqn0t9",
        "outputId": "e1da97c3-ad67-4199-d406-da656ca13ee9"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: RuntimeWarning: invalid value encountered in multiply\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: RuntimeWarning: overflow encountered in exp\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in true_divide\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0, 0.0, 4.141813453058314, 2.5899715694668397, 0.0, 0.0, 0.0, 0.0, 0.8123966924493162, 2.296358299979168]\n",
            "[0.0, 0.0, 3.454871161655702, 3.5054045533010143, 0.0, 0.0, 0.0, 0.0, 0.8065765259174391, 2.744935332457274]\n",
            "[0.0, 0.0, 2.8096817756353385, 4.924794823826106, 0.0, 0.0, 0.0, 0.0, 0.8002733736832464, 3.3607650285539434]\n",
            "[0.0, 0.0, 2.172554514469293, 7.374452733768272, 0.0, 0.0, 0.0, 0.0, 0.7930602296315654, 4.289690540492159]\n",
            "[0.0, 0.0, 1.5492800758611338, 12.083480201176123, 0.0, 0.0, 0.0, 0.0, 0.7846191814677093, 5.817014851944472]\n",
            "[0.0, 0.0, 0.9519019859811486, 22.66851585111859, 0.0, 0.0, 0.0, 0.0, 0.7744536106064899, 8.667841291963557]\n",
            "[0.0, 0.0, 0.40975468496105893, 53.062545887360656, 0.0, 0.0, 0.0, 0.0, 0.7617900942645219, 15.173239094168437]\n",
            "[0.0, 0.0, 0.00455646318535452, 187.36673398343862, 0.0, 0.0, 0.0, 0.0, 0.7457816962225119, 36.324160314018734]\n",
            "[0.30283134662261746, 0.0, 0.0, 1673.2888569299075, 0.08597112961724718, 0.0, 0.0, 0.0, 0.7316760666939102, 179.26145447236883]\n",
            "[0.0, 0.3446407290061184, 0.06541176269395832, 196451.12843757164, 0.0, 0.0, 0.5198436957045802, 2.5168695063948094, 0.9293465884247198, 6723.202868556966]\n",
            "[293.82363060720263, 0.0, 0.0, 25129230871.82117, 191.127457986342, 0.0, 0.0, 0.0, 71.74538481395689, 114911977.44062695]\n",
            "[0.0, 0.0, 103942917.32580866, 2.5026287713446206e+23, 0.0, 0.0, 0.0, 0.0, 3954096421.6255646, 4.420152658864073e+19]\n",
            "[0.0, 0.0, 0.0, 2.3319432941489034e+57, 0.0, 0.0, 0.0, 0.0, 1.0799723692282954e+35, 1.931750838213144e+51]\n",
            "[0.0, 0.0, 0.0, 3.734240344371612e+147, 0.0, 0.0, 0.0, 0.0, 2.7328566549136197e+111, 5.464431759633764e+137]\n",
            "[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: RuntimeWarning: overflow encountered in multiply\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:113: RuntimeWarning: invalid value encountered in subtract\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: RuntimeWarning: invalid value encountered in multiply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
            "[1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-faaa5e3a2026>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neurons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-105-2e08d316448d>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mrow_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma_column1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackpropagation_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-105-2e08d316448d>\u001b[0m in \u001b[0;36mbackpropagation_\u001b[0;34m(self, learning_rate, predicts, y_train)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_neurons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbc_entropy_derivative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m       \u001b[0mderv_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mderv_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mderv_loss\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getbool_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mis_bool_indexer\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0mconvert\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mndarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \"\"\"\n\u001b[0;32m--> 128\u001b[0;31m     if isinstance(key, (ABCSeries, np.ndarray, ABCIndex)) or (\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0mis_array_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     ):\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLjI9IW5TGwN",
        "outputId": "b73be9d9-6367-4b62-c76d-df1c58d1bce4"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([], shape=(100, 0), dtype=float64)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGKs-tdWOxWb",
        "outputId": "a6b65b9d-f519-4ffb-ca4e-2778ef24d7b0"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_valid, X_train2 = X_train[113922:227845], X_train[113922:] \n",
        "y_valid, y_train2 = y_train[113922:227845], y_train[113922:]\n",
        "\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "keras.layers.Dense(1,activation='sigmoid')])\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwegiWTF8Mxf",
        "outputId": "c35a0528-fadb-4eb5-a6cd-05af11bda02c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "7121/7121 [==============================] - 16s 2ms/step - loss: 0.0114 - val_loss: 0.0025\n",
            "Epoch 2/20\n",
            "7121/7121 [==============================] - 21s 3ms/step - loss: 0.0022 - val_loss: 0.0021\n",
            "Epoch 3/20\n",
            "7121/7121 [==============================] - 14s 2ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 4/20\n",
            "7121/7121 [==============================] - 18s 3ms/step - loss: 0.0019 - val_loss: 0.0019\n",
            "Epoch 5/20\n",
            "7121/7121 [==============================] - 14s 2ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 6/20\n",
            "7121/7121 [==============================] - 18s 3ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 7/20\n",
            "7121/7121 [==============================] - 15s 2ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 8/20\n",
            "7121/7121 [==============================] - 18s 3ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 9/20\n",
            "7121/7121 [==============================] - 13s 2ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 10/20\n",
            "7121/7121 [==============================] - 16s 2ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 11/20\n",
            "7121/7121 [==============================] - 13s 2ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 12/20\n",
            "7121/7121 [==============================] - 18s 3ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 13/20\n",
            "7121/7121 [==============================] - 15s 2ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 14/20\n",
            "7121/7121 [==============================] - 17s 2ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 15/20\n",
            "7121/7121 [==============================] - 16s 2ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 16/20\n",
            "7121/7121 [==============================] - 16s 2ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 17/20\n",
            "7121/7121 [==============================] - 15s 2ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 18/20\n",
            "7121/7121 [==============================] - 18s 2ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 19/20\n",
            "7121/7121 [==============================] - 15s 2ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 20/20\n",
            "7121/7121 [==============================] - 18s 3ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "1781/1781 [==============================] - 2s 1ms/step - loss: 0.0019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    try:\n",
        "       return type(X), type(y)\n",
        "    except KeyError as err:\n",
        "       print(err)\n",
        "       raise ValueError('teste')"
      ],
      "metadata": {
        "id": "c9zSBG4CrySP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnmwcQbsvm1n"
      },
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Projeto 4 CIS.ipynb",
      "provenance": [],
      "mount_file_id": "1mvU2beYtDDJIeFvjRrzxprCCdS_i79jH",
      "authorship_tag": "ABX9TyPXexCL0Shq1DEpv+ywbKtX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}